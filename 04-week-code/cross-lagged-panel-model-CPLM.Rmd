
https://osf.io/9p4x5
```{r}
install.packages("lavaan", dependencies = TRUE)
```

```{r library}
#### Load required packages ####

library(foreign)
library(tidyr)
library(dplyr)
library(data.table)
library(corrplot) #plotting correlation matrices
library(lavaan) #for fitting structural equation models
library(semPlot)  #for automatically making diagrams 
library(rmarkdown)
library(knitr)
```
### DATA

#### Example Data

LATENT VARIABLES OF INTEREST:
PSP is perfectionistic self-presentation
  * PSP, composed of three items
SSA is state social anxiety
  * SSA, composed of seven items
established longitudinal measurement invariance over __5 days__

In general, think of the measurement invariance portion as a necessary first step to proceed with hypothesis testing in the cross-lagged panel.

PSP items were measured using a 7-point scale from 1 to 7. 
SSA items were measured using a 5-point scale from 0 to 4.

* convert data to wide format (in which every participant receives a unique row, and each variable receives a unique column - participants and categorical variables SHOULD NOT occur across multiple rows)

__HEY YOU DO NOT RUN THIS CHUNK__
```{r}
#### Create a database with just the necessary variables ####

# 1.1 Load original dataset

mydata <- read.spss("Total Dataset.sav",
					use.value.labels = FALSE,
					to.data.frame = TRUE)

# 1.2 Select only variables of interest

dat_subset_1 <- select(mydata, id, day, psp1, psp2, psp3,
					   psp.mean, ssa1, ssa2, ssa3,
					   ssa4, ssa5, ssa6, ssa7, ssa.mean)

# 1.3 Filter for days 7 - 11 only

dat_subset_2 <- subset(dat_subset_1, day>=7 & day<=11)

# 1.4 Convert to fully long format

dat_long_1 <- gather(dat_subset_2, key = var, value = score, psp1:ssa.mean)

# 1.5 Combine day and var into a new variable

dat_long_1$var.c <- paste(dat_long_1$var, dat_long_1$day)

dat_long_2 <- select(dat_long_1, id, var.c, score)

View(dat_long_2)

# 1.6 Convert to wide format

dat_wide <- spread(dat_long_2, var.c, score)

# 1.7 Correct variable names

name.orig <- colnames(dat_wide)

name.new <- make.names(name.orig, unique = TRUE)

setnames(dat_wide, old = name.orig, new = name.new)

# 1.8 This data set now contains all variables of interest in wide format.

View(dat_wide)

# 1.9 Convert back to long format, with variables of item and score.

# This format is similar, but not identical, to dat_long_2 above.

dat_long <- gather(dat_wide, item, score, psp.mean.10:ssa7.9, factor_key=TRUE)

View (dat_long)

write.csv(dat_wide, file = "Abridged Comp Data.csv")
```

#### Data version 0.0

```{r}
#child_id and mealtime scores
cplm_data <- media_pls %>% 
  mutate(ml_w1 = as.numeric(mealtimes.1),
         ml_w4 = as.numeric(mealtimes.4),
         ml_w6 = as.numeric(mealtimes.6)
         ) %>%
  select(child_id, par_id, ml_w1, ml_w4, ml_w6) 

#adding auditory percentile rank wave 1 
#(the amount of data for this variable is really low)
cplm_data <- left_join(cplm_data, PLS_w1, key = c("child_id")) %>%
  mutate(acpr_w1 = as.numeric(percentile_rank_auditory)) %>% 
  select(child_id, par_id, ml_w1, ml_w4, ml_w6, acpr_w1) 
  

#adding auditory percentile rank wave 4
cplm_data <- left_join(cplm_data, PLS_w4, key = c("child_id")) %>%
  mutate(acpr_w4 = as.numeric(percentile_rank_auditory)) %>% 
  select(child_id, par_id, ml_w1, ml_w4, ml_w6, acpr_w1, acpr_w4) 
  

#adding auditory percentile rank wave 6
cplm_data <- left_join(cplm_data, PLS_w1, key = c("child_id")) %>%
  mutate(acpr_w6 = as.numeric(percentile_rank_auditory)) %>% 
  select(child_id, par_id, ml_w1, ml_w4, ml_w6, acpr_w1, acpr_w4, acpr_w6)  

#CHECKPOINT: baseline wide formatted data complete

#Adding means of variables auditory percentile rank and mealtimes over wave 1 4 6
#ignores NA values in measurements
cplm_data <- cplm_data %>% 
  add_column(acpr_mean = rowMeans(cplm_data[ ,6:8], na.rm = TRUE))

cplm_data <- cplm_data %>% 
  add_column(ml_mean = rowMeans(cplm_data[ ,3:5], na.rm = TRUE)) 
```
#### Data version 1.0
```{r}

```

### Correlation EDA

Reference:
https://quantdev.ssri.psu.edu/sites/qdev/files/LongitudinalMeasurementInvariance_2017_1108.html

```{r}
#correlation matrix of just mealtimes and auditory comprehension across all waves
round(cor(cplm_data[,3:10]),2)
```
```{r}
#correlation matrix of just mealtimes and auditory comprehension across all waves
corrplot(cor(cplm_data[,3:10]), order = "original", tl.col='black', tl.cex=.75) 
```

### CREATING THE MODELS

BIG PICTURE GOAL: Compare nested versions of our CPLM using CFA (confirmatory factor analysis) to determine the most appropriate parameters for our final structural model

PROBLEM: I'VE ALREADY PRESELECTED THE PARAMETERS FOR THE FINAL STRUCTURAL MODEL
    Unless the parameter selection is based on derived covariates from the one's I've already selected

1) =~ , which is used for factor loadings, and can be thought of as “is measured by;”
2) ~ , which is used for regression formulas, and can be thought of as “is regressed on;”
3) ~~ , which is used for defining variance and residual covariance, and can be thought of as “varies with;”and 
4) ~ 1, which is a special notation for defining intercepts.
5) true cross-lagged model where directionality is assumed

5 DAYS: 7 8 9 10 11

__What are latent variables?__ (this is technically a latent variable model I suppose)
  + latent variables are variables that are not directly observed but are rather inferred through a mathematical model from other variables that are observed (directly measured)
  + also known as hypothetical variables or hypothetical constructs
  __+ a potential latent variable for this model would be child development__
  
__What are factor loadings?__
  + they show how representative each item is of its latent factor (for us it is child development)
  
__What is a Confirmatory Factor Analysis (CFA)?__
  + confirmatory factor analysis is a statistical technique that allows us to test whether clusters of items in our measure are indeed reflective of the latent construct to which we have assigned them.
  + we use a confirmatory factor analysis to test fo r measurement invariance
  
__What is Measurement Invariance (MI)?__
  + measurement invariance is upheld in a study when all partecipants interpret questions asked them all the same way as well as the underlying latent factor in the same way
  +This is an incredibly important assumption in longitudinal studies incorporating latent variables

__General Parameters of Concern for this model are:__
  1) factor loadings, which show how representative each item is of its latent factor; 
  2) intercepts, which relate to the mean levels of each item; and 
  3) residual variances, which represent the other unexplained influences predicting item responses besides latent variables. 

It seems like the next step is to DEFINE the __Configural Model__, this requires:
  1. mealtimes (ml) factor loadings to be defined for each wave
  2. mealtimes (ml) variance constrained to 1 for each wave
  3. auditory (acpr) factor loadings to be defined for each wave
  4. auditory (acpr) variance constrained to 1 for each wave

__How are Factor Loadings Defined?__ (how to define factor loadings for a configural model)
  + Conceptual Understanding: A factor loading is how related a variable is to a theoretical factor that is implicitely being measured through a series of specific measurements (denoted by the variable). Factor loadings express the relation of each variable to the underlying factor. Observed variables have a common variance that a factor explains and this is quantified by an eigenvalue.
  + factor loadings can be interpreted like/as standardized regression coefficients (specifically, like correlation with a factor)
  + https://www.theanalysisfactor.com/factor-analysis-1-introduction/
  + Factor Loadings seems to be defined through a Multiple Factor Analysis, essentially it seems I need to perform a Factor Analysis
  + https://www.statisticshowto.com/factor-analysis/

__How to Perform a Factor Analysis to define Factors and their Factor Loadings (correlation):__
  + 
  + https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/factor-analysis/
  
__Considering we are trying to confirm a conceptual understanding from the PI we want to perform a Confirmatory Factor Analysis:__
  + https://methodenlehre.github.io/SGSCLM-R-course/cfa-and-sem-with-lavaan.html
  + HOLY SHIT I JUST FIGURED OUT HOW TO DEFINE THE LATENT FACTORS THEY ARE DEFINED BY THE SUBQUESTIONS MEASURING THE LATENT FACTORS HOLY SHIT
  
__Questions about LAVAAN syntax can be answered here:__
  + https://lavaan.ugent.be/tutorial/tutorial.pdf
  
__What is the purpose of NA* in specifying the latent variable__
  + Answered in "More about the syntax" (https://lavaan.ugent.be/tutorial/tutorial.pdf)
  + LAVANN automatically sets the first coefficient (factor loading) of a term/indicator to be 1, to have it be estimated by the model (aka forcing the loading factor to be free) instead we need to specify NA*, the following is an example: 
  speed =~ NA*x7 + x8 + x9

---
CHECKPOINT

### Error Structure
Quote:
"Next, we define our error structure, which is complex. Because it takes up so many lines, we're doing this first to call it up as an object in our syntax later. This will just make our code tidier and shorter overall. Note also that we constrain our error term covariances to equality across waves. This greatly simplifies an already complex model. Note also that lavaan objects are saved as strings, not formulas: This will be relevant in the next step."

__Here I need to constrain the residual covariances to equality across waves__
  + how to calculate the residual covariance for each variable (question variable)
  + unless I don't need to assign specific variables for this value since it isn't in the adjusted dataset they provided, plus it would be the only unknown in the equations below
  + most efficient course of action would be to just rerewrite the equations below with our variables

```{r errorstructure}

# Error term covariances constrained across waves
# Observation: every question at every timepoint covaries with the same question at a different timepoint

errorstructure <- 
'
#q1 (mt05c) mealtimes all time points (order doesnt matter), time isnt specified in the covariance term

mt05c_w1 ~~ mt05ccov*mt05c_w4
mt05c_w1 ~~ mt05ccov*mt05c_w6
mt05c_w4 ~~ mt05ccov*mt05c_w6

#q2 (mt05d) mealtimes all time points

mt05d_w1 ~~ mt05dcov*mt05d_w4
mt05d_w1 ~~ mt05dcov*mt05d_w6
mt05d_w4 ~~ mt05dcov*mt05d_w6

#q3 (mtz05jz) mealtimes all time points

mtz05jz_w1 ~~ mtz05jzcov*mtz05jz_w4
mtz05jz_w1 ~~ mtz05jzcov*mtz05jz_w6
mtz05jz_w4 ~~ mtz05jzcov*mtz05jz_w6


#q1 (plsecpr) expressive communication all time points

plsecpr_w1 ~~ plsecprcov*plsecpr_w4
plsecpr_w1 ~~ plsecprcov*plsecpr_w6
plsecpr_w4 ~~ plsecprcov*plsecpr_w6

#q2 (plsacpr) pls auditory comprehension all time points

plsacpr_w1 ~~ plsacprcov*plsacpr_w4
plsacpr_w1 ~~ plsacprcov*plsacpr_w6
plsacpr_w4 ~~ plsacprcov*plsacpr_w6
'


```

### Configural Model
```{r}
configural_v1 <-
  
'
# (ML) MEALTIMES factor loadings defined
ML_W1 =~ NA*mt05c_w1 + mt05d_w1 + mtz05cjz_w1
ML_W4 =~ NA*mt05c_w4 + mt05d_w4 + mtz05cjz_w4
ML_W6 =~ NA*mt05c_w6 + mt05d_w6 + mtz05cjz_w6

# (ML) MEALTIMES variance constrained to 1
ML_W1 ~~ 1*ML_W1
ML_W4 ~~ 1*ML_W4
ML_W6 ~~ 1*ML_W6

# (PLS) RECEPTIVE AND EXPRESSIVE COMMUNICATION SKILLS PERCENTILE RANK factor loadings defined
PLS_W1 =~ NA*plsecpr_w1 + plsacpr_w1
PLS_W4 =~ NA*plsecpr_w4 + plsacpr_w4
PLS_W6 =~ NA*plsecpr_w6 + plsacpr_w5

# (PLS) RECEPTIVE AND EXPRESSIVE COMMUNICATION SKILLS PERCENTILE RANK variance constrained to 1
PLS_W1 ~~ 1*PLS_W1
PLS_W4 ~~ 1*PLS_W4
PLS_W6 ~~ 1*PLS_W6
'
configural.model <- paste(configural.v1, errorstructure, sep = ' ', collapse 
= NULL)
```

