```{r}
library(forcats)
library(haven)
library(readxl)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(janitor)
```

```{r}
model_w2 <- readRDS(file="../data/model_w2.dta")
model_w6 <- readRDS(file="../data/model_w6.dta")
valuable_dataset <- readRDS(file="../data/valuable_dataset.dta")
```

```{r}
PLS_data <- readRDS(file="../data/PLS_data.dta")
BIT_data <- readRDS(file="../data/BIT_data.dta")
media_data <- readRDS(file="../data/media_data.dta")
demography <- readRDS(file="../data/demography.dta")
```

### Creating tables

Thoughts/Ideas:
* explore an ANOVA model to see if the hypothesized predictors that have factors are actually significant
* definitely check out the most efficient linear model according to Aubree's ML code that optimized for certain parameters
* ANCOVA model is mixes linear regression with anova, this ultimately may be a good idea to implement since MEDIA, PLS, BITSEA, Income are quantitative (numerical) and Ethnicity, Education are qualitative (categorical)

##### creating wave6 data for linear models

Here I've just started by creating a complete dataset for wave 6 for 3 datasets:
1. media
2. BITSEA
3. PLS

```{r}
#creating wave 6 dataset complete with 
wave6 <- inner_join(mt_w6_cleaned, model_w6, key = c(par_id, child_id))
wave6 <- inner_join(wave6, PLS_data, key = c(par_id, child_id) )

wave6 <- wave6 %>% 
  filter(wave == 6) %>% 
  glimpse()

#wave6 <- inner_join(wave6, valuable_dataset, key = c(par_id, child_id) )
wave6 %>% 
  glimpse()
```

##### creating table for ANOVA model

Here I added education to try and create an ANOVA model to see if we get a better quality model.

```{r}
#education doesn't change across waves (assumption)
ed <- valuable_dataset %>% 
  select(highest_degree_completed, child_id, par_id)

wave6 <- inner_join(wave6, ed, key = c(par_id, child_id) )

wave6 %>% 
  glimpse()

#here I'm getting rid of NA values in the education factor
wave6 <- wave6 %>% 
  filter(!is.na(highest_degree_completed)) %>% 
  glimpse()

```

AH YES CLARITY:

```{r}
# wave 1 media and pls 
pls_media_w1 <- valuable_dataset %>% 
  filter(wave.y.y == 1) %>% 
  mutate(wave = as.factor(wave.y.y)) %>% 
  select(wave, child_id, par_id, total_score, daily_use) 

# wave 6 media and pls 
pls_media_w6 <- wave6 %>% 
  select(wave, child_id, par_id, total_score, daily_use)

#this may have done it, just joining with child and parent ids
anova_table <- full_join(pls_media_w1, pls_media_w6 ,key = c(child_id, par_id))

#now there are missing value codes, NAs, and wave 4 data (for some reason??), I need to get rid of:
anova_table <- anova_table %>% 
  na.omit() %>% 
  filter( 
    total_score != -111,
    total_score != -222,
    total_score != -333,
    total_score != -444,
    total_score != -555,
    total_score != -666,
    total_score != -777,
    total_score != -888,
    total_score != -999,
    wave != 4
    )

#now we need the same number of child ids for wave 6 and wave 1
anova_table %>% 
  summary()

#need to only include parent ids that exist both in wave 1 and in wave 6
anova_table <- anova_table %>% 
  group_by(par_id) %>% 
  filter(n() == 2)

# now i need to create a new column factor that puts a daily score measurement as low, med high
#but first I need to see the distribution of daily media usage
ggplot(data = anova_table,
       aes(x = daily_use)) +
  geom_histogram(color = "white",
                 fill = "darkred")
```



### First ONE-WAY ANOVA model:

__ANOVA takes into account variability within groups and between groups, by comparing means among groups.__
One-way ANOVA is appropriate when there are multiple measurements of the same treatment or thing across different groups...maybe we may want to group by wave?

Look at the _mean_ PLS, Media scores for each wave (1, 4, 6) in boxplots.

So then maybe the appropriate question would be (LEC9 - STATS120C):
Are the means of PLS scores different among different groups of media usage (low, med, high) across different waves? 

Since each group will not have the same size this one-way ANOVA is for _unbalanced groups_(LEC11, LEC12 -120C). 
^ ANOVA may still be balanced since 1. we are looking at the mean of means for PLS scores and 2. we might bootstrap pls scores so CLT applies, hence sample sizes will be made the same for each media use group.

_Assumptions are consistent regardless of whether ANOVA is balanced or not:_
1. responses follow a normal distribution 
  * PLS scores histograms look approx. normal, but if take the sample means of pls scores in each media category and bootstrap then according to CLT we should be able to say that the sample means follow a approx normal distribution (check out ppt for wk2 for origial histogram of pls scores (not means of scores))

2. Observations are independent within and between groups
  * questionable as media usage and receptive and expressive communication skills are likely dependent (or are they? potential HYPOTHESIS TEEESTT BBBAABBYYY) 

3. errors/residuals are normally distributed with a constant variance, expectation 0
  * totally unknown

Estimated coefficient is not significant, for an example look at 120C discussion 6 for ONE WAY ANOVA


```{r}
aov_model <- aov(total_score ~ highest_degree_completed, wave6)

summary(aov_model)
```



##### Linear Regression Models are Trash:

_Need to put notes on how we quantify the quality of a linear model here._
!!!read this later!!!!:
https://www.investopedia.com/ask/answers/012615/whats-difference-between-rsquared-and-adjusted-rsquared.asp

Multiple Linear regression doesn't get an adjusted r-squared larger than ~0.040. In otherwords these models have no predictive power since the data isn't linear.

```{r}

w6_dbby_pls_model <- 
  lm(total_score ~ digital_babysitting + daily_use + discipline_behavior_management + behavior_management + tv_exposure + n_devices +, data = wave6)

summary(w6_dbby_pls_model)
```

This maps PLS scores to years of school completed (which has a ridiculous amount of NA values), pretty much trash.

```{r}
#model <- lm(total_score ~ years_school_complete  , data = wave6)
#summary(model)
```

More relevant variables but this adjusted r-squared values makes me very sad:

```{r}
w6_media_bitsea_model <- 
  lm(total_score ~ daily_use , data = wave6)

summary(w6_media_pls_model)
```

##### Graphs for Week 2 powerpoint presentation:

```{r}
responses %>%
  inner_join(predictors, by = c("par_id", "child_id")) %>%
  inner_join(demographics, by = c("par_id", "child_id")) %>%
  ggplot(aes(MT_daily_use, BITprobavg_w6)) +
  labs(title = "Wave 6: Daily Media Usage vs Social Problem Score For Mothers & Fathers",
       x = "Daily Media Use Average Score",
       y = "Infant's Social Problem Average Score") +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~father)
```


Heatmap of all relevant predictors that are NOT media, bitsea, or pls:

```{r}
ggplot(filter(valuable_dataset, highest_degree_completed != "NA", par_ethnicity != "NA", household_income_numerical != "NA", par_ethnicity != "Middle Eastern", par_ethnicity != "Other"), aes(x = par_ethnicity, y = highest_degree_completed, fill = household_income_numerical)) +
  labs(title = "Heat map of Demographic Predictors",
       x = "Parent Ethnicity",
       y = "Education Background") +
  geom_tile() +
  scale_fill_gradientn(name = "", colors = hcl.colors(12, "Purple-Green")) +
  scale_x_discrete(name = "") +
  scale_y_discrete(name = "") +
  theme_dark() +
theme(axis.text.x = element_text(angle = 10)) + 
  guides(fill = guide_colourbar(barwidth = 0.5,
                                barheight = 15, title = "Household Income")) 
```

I think this is Chandra's code for the correlation matrix, maybe not, who knows, will maybe get back to this later:
```{r}
#socioeconomic status (qual/quant) and daily use (quant) & parenting class (qual)

#responses %>%
#  inner_join(predictors, by = c("par_id", "child_id")) %>%
#  inner_join(demographics, by = c("par_id", "child_id")) %>%
#  join
#  ggplot(aes(MT_daily_use, household_income_numerical)) +
#  labs(title = "Wave 6: Daily Media Usage vs Social Problem Score For Mothers & Fathers",
#       x = "Daily Media Use Average Score",
#       y = "Infant's Social Problem Average Score") +
#  geom_point() +
#  geom_smooth(method = "lm") +
#  facet_wrap(~parenting_class_taken)
```

```{r}
## daily use vs problem score - highest degree completed

#responses %>%
#  inner_join(predictors, by = c("par_id", "child_id")) %>%
#  inner_join(demographics, by = c("par_id", "child_id")) %>%
#  ggplot(aes(MT_daily_use, BITprobavg_w2)) +
#  labs(title = "Wave 2: Daily Media Usage vs Social Problem Score For Mothers & Fathers",
#       x = "Daily Media Use Average Score",
#       y = "Infant's Social Problem Average Score") +
#  geom_point() +
# geom_smooth(method = "lm") +
#  facet_wrap(~father)
```
